{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706c8fba",
   "metadata": {},
   "source": [
    "\n",
    "# PROs preprocess:\n",
    "\n",
    "\n",
    "received the raw data file from Sophia, who did the first step of preprocessing\n",
    "\n",
    "\n",
    "Yiyu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caadc333-2dd0-4c77-94ae-6b3374b09bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /Users/yiyuwang/anaconda3\n",
      "actigraphy               /Users/yiyuwang/anaconda3/envs/actigraphy\n",
      "flywheel                 /Users/yiyuwang/anaconda3/envs/flywheel\n",
      "neuroimaging_analysis     /Users/yiyuwang/anaconda3/envs/neuroimaging_analysis\n",
      "prediction_env        *  /Users/yiyuwang/anaconda3/envs/prediction_env\n",
      "stabl                    /Users/yiyuwang/anaconda3/envs/stabl\n",
      "                         /Users/yiyuwang/fsl\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda env list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9e34a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, sys\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import string\n",
    "import collections\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 2024\n",
    "NROI = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9967b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local directory\n",
    "project_dir = '/users/yiyuwang/Desktop/SNAPL/Projects/HEAL_prediction'\n",
    "\n",
    "# # directory on sherlock\n",
    "# project_dir = '/scratch/users/yiyuw/Projects/HEAL_prediction'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29dd7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate reliability between two runs:\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "    \n",
    "def FormatSubID(source_id):\n",
    "    # Make it a string\n",
    "    source_id = str(source_id)\n",
    "    if \"bio\" in source_id:   \n",
    "        # check if the sub number is four digit:\n",
    "        sub_num = int(source_id.split(\"bio\")[1])\n",
    "        formatted_id = \"bio\" + \"{:04}\".format(sub_num)\n",
    "        \n",
    "    elif \"Bio\" in source_id:\n",
    "        # check if the sub number is four digit:\n",
    "        sub_num = int(source_id.split(\"Bio\")[1])\n",
    "        formatted_id = \"bio\" + \"{:04}\".format(sub_num)\n",
    "        \n",
    "    elif \"BIO-\" in source_id:\n",
    "        # check if the sub number is four digit:\n",
    "        sub_num = int(source_id.split(\"BIO-\")[1])\n",
    "        formatted_id = \"bio\" + \"{:04}\".format(sub_num)\n",
    "    elif \"BIO\" in source_id:\n",
    "        # check if the sub number is four digit:\n",
    "        sub_num = int(source_id.split(\"BIO\")[1])\n",
    "        formatted_id = \"bio\" + \"{:04}\".format(sub_num)    \n",
    "        \n",
    "    elif type(int(source_id))==int: #sub_id just numbers\n",
    "        sub_num = int(source_id)\n",
    "        formatted_id = \"bio\" + \"{:04}\".format(sub_num)\n",
    "    \n",
    "    else: # everything else just return empty string\n",
    "        formatted_id = \"\"\n",
    "    \n",
    "    return formatted_id\n",
    "\n",
    "def FormatSession(session):\n",
    "    if 'baseline' in session:\n",
    "        formatted_session = 'baseline'\n",
    "    elif '1_month' in session:\n",
    "        formatted_session = 'month1'\n",
    "    elif '2_month' in session:\n",
    "        formatted_session = 'month2'    \n",
    "    elif '3_month' in session:\n",
    "        formatted_session = 'month3'\n",
    "    elif '6_month' in session:\n",
    "        formatted_session = 'month6'\n",
    "    else:\n",
    "        formatted_session = \"\"\n",
    "    return formatted_session        \n",
    "\n",
    "def FormatSessionPromis(session):\n",
    "    if session == 'b':\n",
    "        formatted_session = 'baseline'\n",
    "    elif session == '1':\n",
    "        formatted_session = 'month1'\n",
    "    elif session == '2':\n",
    "        formatted_session = 'month2'    \n",
    "    elif session == '3':\n",
    "        formatted_session = 'month3'\n",
    "    elif session == '6':\n",
    "        formatted_session = 'month6'\n",
    "    else:\n",
    "        formatted_session = \"\"\n",
    "    return formatted_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "401f0ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>redcap_survey_identifier</th>\n",
       "      <th>survey_welcome_timestamp</th>\n",
       "      <th>date_survey_taken</th>\n",
       "      <th>survey_welcome_complete</th>\n",
       "      <th>demographics_timestamp</th>\n",
       "      <th>date_taken</th>\n",
       "      <th>brthdtc</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>fcrtracking_lastname</th>\n",
       "      <th>fcrtracking_mrn</th>\n",
       "      <th>id_screening</th>\n",
       "      <th>fcrtracking_dob</th>\n",
       "      <th>fcrtracking_age</th>\n",
       "      <th>fcrtracking_phone</th>\n",
       "      <th>fcrtracking_email</th>\n",
       "      <th>fcrtracking_city</th>\n",
       "      <th>fcrtracking_zip</th>\n",
       "      <th>identifiers_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bio0001</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/4/22 20:07</td>\n",
       "      <td>4/4/22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4/4/22 20:10</td>\n",
       "      <td>4/4/22</td>\n",
       "      <td>6/6/56</td>\n",
       "      <td>65.827498</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>janeanmike@yahoo.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bio0001</td>\n",
       "      <td>screening__enrollm_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Felch</td>\n",
       "      <td>30864458.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/6/56</td>\n",
       "      <td>66.0</td>\n",
       "      <td>(831) 521-2189</td>\n",
       "      <td>janeanmike@yahoo.com</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>95123.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bio0001</td>\n",
       "      <td>1_month_followup_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/5/22 12:18</td>\n",
       "      <td>5/5/22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bio0001</td>\n",
       "      <td>2_month_followup_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/9/22 11:29</td>\n",
       "      <td>6/9/22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bio0001</td>\n",
       "      <td>3_month_followup_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/22 11:08</td>\n",
       "      <td>6/30/22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 693 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  study_id         redcap_event_name  redcap_survey_identifier  \\\n",
       "0  Bio0001            baseline_arm_1                       NaN   \n",
       "1  Bio0001  screening__enrollm_arm_1                       NaN   \n",
       "2  Bio0001    1_month_followup_arm_1                       NaN   \n",
       "3  Bio0001    2_month_followup_arm_1                       NaN   \n",
       "4  Bio0001    3_month_followup_arm_1                       NaN   \n",
       "\n",
       "  survey_welcome_timestamp date_survey_taken  survey_welcome_complete  \\\n",
       "0             4/4/22 20:07            4/4/22                      2.0   \n",
       "1                      NaN               NaN                      NaN   \n",
       "2             5/5/22 12:18            5/5/22                      2.0   \n",
       "3             6/9/22 11:29            6/9/22                      2.0   \n",
       "4            6/30/22 11:08           6/30/22                      2.0   \n",
       "\n",
       "  demographics_timestamp date_taken brthdtc        age  ...  \\\n",
       "0           4/4/22 20:10     4/4/22  6/6/56  65.827498  ...   \n",
       "1                    NaN        NaN     NaN        NaN  ...   \n",
       "2                    NaN        NaN     NaN        NaN  ...   \n",
       "3                    NaN        NaN     NaN        NaN  ...   \n",
       "4                    NaN        NaN     NaN        NaN  ...   \n",
       "\n",
       "   fcrtracking_lastname  fcrtracking_mrn id_screening  fcrtracking_dob  \\\n",
       "0                   NaN              NaN          NaN              NaN   \n",
       "1                 Felch       30864458.0          NaN           6/6/56   \n",
       "2                   NaN              NaN          NaN              NaN   \n",
       "3                   NaN              NaN          NaN              NaN   \n",
       "4                   NaN              NaN          NaN              NaN   \n",
       "\n",
       "   fcrtracking_age  fcrtracking_phone     fcrtracking_email  fcrtracking_city  \\\n",
       "0              NaN                NaN  janeanmike@yahoo.com               NaN   \n",
       "1             66.0     (831) 521-2189  janeanmike@yahoo.com          San Jose   \n",
       "2              NaN                NaN                   NaN               NaN   \n",
       "3              NaN                NaN                   NaN               NaN   \n",
       "4              NaN                NaN                   NaN               NaN   \n",
       "\n",
       "   fcrtracking_zip  identifiers_complete  \n",
       "0              NaN                   0.0  \n",
       "1          95123.0                   2.0  \n",
       "2              NaN                   NaN  \n",
       "3              NaN                   NaN  \n",
       "4              NaN                   NaN  \n",
       "\n",
       "[5 rows x 693 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pro_df = pd.read_csv(f'{project_dir}/Data/raw_data/PROs/BiomarkersPatientRep_DATA_2024-06-01_1201.csv')\n",
    "pro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c699b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpaq_willingness_7_rev</th>\n",
       "      <th>cpaq_willingness_8_rev</th>\n",
       "      <th>cpaq_willingness_6_rev</th>\n",
       "      <th>cpaq_willingness_norev</th>\n",
       "      <th>time</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>baseline</td>\n",
       "      <td>bio0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>month1</td>\n",
       "      <td>bio0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>month2</td>\n",
       "      <td>bio0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>month3</td>\n",
       "      <td>bio0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>month6</td>\n",
       "      <td>bio0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cpaq_willingness_7_rev  cpaq_willingness_8_rev  cpaq_willingness_6_rev  \\\n",
       "0                    19.0                    20.0                    18.0   \n",
       "2                    12.0                    13.0                    12.0   \n",
       "3                    11.0                    12.0                     9.0   \n",
       "4                    12.0                    13.0                    13.0   \n",
       "5                     9.0                    10.0                     7.0   \n",
       "\n",
       "   cpaq_willingness_norev      time participant_id  \n",
       "0                    12.0  baseline        bio0001  \n",
       "2                    11.0    month1        bio0001  \n",
       "3                     6.0    month2        bio0001  \n",
       "4                     9.0    month3        bio0001  \n",
       "5                     8.0    month6        bio0001  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_df = pd.read_csv(f'{project_dir}/Data/raw_data/PROs/BiomarkersPatientRep_DATA_2024-06-01_1201.csv')\n",
    "\n",
    "pro_df['cpaq_8_rev'] =  8 - pro_df['cpaq_8']\n",
    "pro_df['cpaq_7_rev'] = 7 - pro_df['cpaq_8']\n",
    "pro_df['cpaq_6_rev'] = 6 - pro_df['cpaq_6']\n",
    "\n",
    "\n",
    "score_df = pd.DataFrame({'participant_id': pro_df['study_id'], 'time': pro_df['redcap_event_name']})\n",
    "score_df['participant_id'] = score_df['participant_id'].apply(FormatSubID)\n",
    "score_df['time'] = score_df['time'].apply(FormatSession)\n",
    "# if time or participant id is empty, remove the row\n",
    "score_df = score_df[score_df['participant_id'] != \"\"]\n",
    "score_df = score_df[score_df['time'] != \"\"]\n",
    "score_df['cpaq_willingness_7_rev'] =  pro_df[['cpaq_' + str(i) for i in [2,4,7]]].sum(axis=1) + pro_df['cpaq_7_rev']\n",
    "score_df['cpaq_willingness_8_rev'] = pro_df[['cpaq_' + str(i) for i in [2,4,7]]].sum(axis=1) + pro_df['cpaq_8_rev']\n",
    "score_df['cpaq_willingness_6_rev'] = pro_df[['cpaq_' + str(i) for i in [2,4,7]]].sum(axis=1) + pro_df['cpaq_6_rev']\n",
    "score_df['cpaq_willingness_norev']= pro_df[['cpaq_' + str(i) for i in [2,4,7, 8]]].sum(axis=1)\n",
    "\n",
    "pro_df[['cpaq_8_rev', 'cpaq_7_rev', 'cpaq_6_rev', 'cpaq_8']].head()\n",
    "\n",
    "score_df[['cpaq_willingness_7_rev', 'cpaq_willingness_8_rev', 'cpaq_willingness_6_rev', 'cpaq_willingness_norev', 'time', 'participant_id']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9de754ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['study_id', 'redcap_event_name', 'redcap_survey_identifier',\n",
       "       'survey_welcome_timestamp', 'date_survey_taken',\n",
       "       'survey_welcome_complete', 'demographics_timestamp', 'date_taken',\n",
       "       'brthdtc', 'age',\n",
       "       ...\n",
       "       'fcrtracking_dob', 'fcrtracking_age', 'fcrtracking_phone',\n",
       "       'fcrtracking_email', 'fcrtracking_city', 'fcrtracking_zip',\n",
       "       'identifiers_complete', 'cpaq_8_rev', 'cpaq_7_rev', 'cpaq_6_rev'],\n",
       "      dtype='object', length=696)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b9f738",
   "metadata": {},
   "source": [
    "# scoring raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eef66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame({'participant_id': pro_df['study_id'], 'time': pro_df['redcap_event_name']})\n",
    "score_df['participant_id'] = score_df['participant_id'].apply(FormatSubID)\n",
    "score_df['time'] = score_df['time'].apply(FormatSession)\n",
    "# if time or participant id is empty, remove the row\n",
    "score_df = score_df[score_df['participant_id'] != \"\"]\n",
    "score_df = score_df[score_df['time'] != \"\"]\n",
    "\n",
    "\n",
    "# Chronic Pain Acceptance Questionnaire\n",
    "# reverse score item 8 (range = 0-6)\n",
    "pro_df['cpaq_8'] = 6 - pro_df['cpaq_8']\n",
    "\n",
    "cpaq_items = ['cpaq_' + str(i) for i in [1,2,3,4,5,6,7,8]]\n",
    "# if all the items have been answered, sum the score\n",
    "row_mask = pro_df[cpaq_items].apply(lambda row: row.isnull().sum() == 0, axis=1)\n",
    "\n",
    "# replace False with nan such that it will return an nan if any of the items is missing\n",
    "row_mask = row_mask.replace(False, np.nan)\n",
    "# sum the score\n",
    "score_df['cpaq_willingness'] = pro_df[['cpaq_' + str(i) for i in [2,4,7,8]]].sum(axis=1) * row_mask\n",
    "score_df['cpaq_activity_engagement'] = pro_df[['cpaq_' + str(i) for i in [1,3,5,6]]].sum(axis=1) * row_mask\n",
    "score_df['cpaq_total'] = score_df['cpaq_willingness'] + score_df['cpaq_activity_engagement']\n",
    "\n",
    "\n",
    "\n",
    "# Pain Catastrophizing Scale\n",
    "pcs_items = ['pcs_' + str(i) for i in range(1,14)]  \n",
    "row_mask = pro_df[pcs_items].apply(lambda row: row.isnull().sum() == 0, axis=1)\n",
    "\n",
    "# replace False with nan such that it will return an nan if any of the items is missing\n",
    "row_mask = row_mask.replace(False, np.nan)\n",
    "\n",
    "score_df['pcs_total'] = pro_df[pcs_items].sum(axis=1) * row_mask\n",
    "score_df['pcs_rumination'] = pro_df[['pcs_8', 'pcs_9', 'pcs_10', 'pcs_11']].sum(axis=1) * row_mask\n",
    "score_df['pcs_magnification'] = pro_df[['pcs_6', 'pcs_7', 'pcs_13']].sum(axis=1) * row_mask\n",
    "score_df['pcs_hopelessness'] = pro_df[['pcs_1', 'pcs_2', 'pcs_3', 'pcs_4', 'pcs_5', 'pcs_12']].sum(axis=1) * row_mask\n",
    "\n",
    "\n",
    "#  'scltotal', 'pseqtotal', 'gadtotal', 'phqtotal', 'tsktotal'\n",
    "scl_items = ['scl90_' + str(i) for i in range(1,12)]  \n",
    "row_mask = pro_df[scl_items].apply(lambda row: row.isnull().sum() == 0, axis=1)\n",
    "row_mask = row_mask.replace(False, np.nan)\n",
    "score_df['scltotal'] = pro_df[scl_items].sum(axis=1) * row_mask\n",
    "\n",
    "pseq_items = ['pseq_' + str(i) for i in range(1,11)]\n",
    "row_mask = pro_df[pseq_items].apply(lambda row: row.isnull().sum() == 0, axis=1)\n",
    "row_mask = row_mask.replace(False, np.nan)\n",
    "score_df['pseqtotal'] = pro_df[pseq_items].sum(axis=1) * row_mask\n",
    "\n",
    "gad_items = ['gad_' + str(i) for i in [1,2]]\n",
    "row_mask = pro_df[gad_items].apply(lambda row: row.isnull().sum() == 0, axis=1)\n",
    "row_mask = row_mask.replace(False, np.nan)\n",
    "score_df['gadtotal'] = pro_df[gad_items].sum(axis=1) * row_mask\n",
    "\n",
    "tsk_items = ['tsk_' + str(i) for i in range(1,12)]\n",
    "row_mask = pro_df[tsk_items].apply(lambda row: row.isnull().sum() == 0, axis=1)\n",
    "row_mask = row_mask.replace(False, np.nan)\n",
    "score_df['tsktotal'] = pro_df[tsk_items].sum(axis=1) * row_mask\n",
    "\n",
    "\n",
    "# list of variables that can be taken directly\n",
    "direct_variables = ['working_not_working', 'pain_frequency', 'life_limitation', 'describe_pain_number', 'phq_2',\n",
    "                    'taps_1', 'taps_2', 'taps_3', 'taps_4',\t'taps_5', 'ppiy_1', 'ppiy_2a', 'ppiy_3a']\n",
    "score_df[direct_variables] = pro_df[direct_variables]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cc8de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df[['participant_id', 'time', 'cpaq_willingness', 'cpaq_total', 'cpaq_activity_engagement']].to_csv('cpaq.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a900ce9",
   "metadata": {},
   "source": [
    "# sleep duration: preliminary processing\n",
    "\n",
    "sleep duration will be scored by hand because open texts are not reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b7a5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pro_df[['study_id', 'redcap_event_name', 'sleepduration']]\n",
    "sleep_df['participant_id'] = sleep_df['study_id'].apply(FormatSubID)\n",
    "sleep_df['time'] = sleep_df['redcap_event_name'].apply(FormatSession)\n",
    "sleep_df = sleep_df[sleep_df['participant_id'] != \"\"]\n",
    "sleep_df = sleep_df[sleep_df['time'] != \"\"]\n",
    "sleep_df.to_csv(f'{project_dir}/Data/raw_data/PROs/sleep_duration.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68dbc4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  study_id       redcap_event_name sleepduration participant_id      time  \\\n",
      "0  Bio0001          baseline_arm_1             7        bio0001  baseline   \n",
      "2  Bio0001  1_month_followup_arm_1             6        bio0001    month1   \n",
      "3  Bio0001  2_month_followup_arm_1             6        bio0001    month2   \n",
      "4  Bio0001  3_month_followup_arm_1             6        bio0001    month3   \n",
      "5  Bio0001  6_month_followup_arm_1             6        bio0001    month6   \n",
      "\n",
      "   Converted  \n",
      "0        7.0  \n",
      "2        6.0  \n",
      "3        6.0  \n",
      "4        6.0  \n",
      "5        6.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean_value(value):\n",
    "    # Remove unwanted characters\n",
    "    cleaned_value = re.sub(r'[^\\d.-]', '', value)\n",
    "    # Fix multiple periods issue\n",
    "    if cleaned_value.count('.') > 1:\n",
    "        parts = cleaned_value.split('.')\n",
    "    \n",
    "        cleaned_value = parts[0] + '.' + ''.join(parts[1:])\n",
    "    return cleaned_value\n",
    "\n",
    "def convert_to_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    if isinstance(value, pd.Timestamp):\n",
    "        return np.nan\n",
    "    if isinstance(value, str):\n",
    "        value = value.lower().replace('hours', 'hr').replace('hour', 'hr').replace('minutes', 'min').replace('minute', 'min')\n",
    "        if 'hr' in value and 'min' in value:\n",
    "            try:\n",
    "                hr_part = float(re.search(r'(\\d+)\\s*hr', value).group(1))\n",
    "                min_part = float(re.search(r'(\\d+)\\s*min', value).group(1))\n",
    "                return hr_part + (min_part / 60)\n",
    "            except:\n",
    "                return np.nan\n",
    "        value = clean_value(value)\n",
    "        if '-' in value:\n",
    "            try:\n",
    "                start, end = map(float, value.split('-'))\n",
    "                return (start + end) / 2\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        elif value.replace('.', '', 1).isdigit():\n",
    "            return float(value)\n",
    "        else:\n",
    "            return np.nan\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Load the Excel file\n",
    "\n",
    "df = sleep_df\n",
    "\n",
    "# Apply the conversion function to the dataframe\n",
    "df['Converted'] = df['sleepduration'].apply(convert_to_numeric)\n",
    "\n",
    "# replace with nan for anything that is longer than 24 hours\n",
    "# df.loc[df['Converted'] > 24, 'Converted'] = np.nan\n",
    "\n",
    "# Display the converted dataframe\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "#!!!!!!!!!!! turn this to false once hand processed the data!!!!!!!!!!!!!!!!!!\n",
    "save = False\n",
    "if save:\n",
    "    df.to_csv(f'{project_dir}/Data/raw_data/PROs/converted_sleep_duration.csv', index=False)\n",
    "# df still need to be manually checked for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18478606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>time</th>\n",
       "      <th>cpaq_willingness</th>\n",
       "      <th>cpaq_activity_engagement</th>\n",
       "      <th>cpaq_total</th>\n",
       "      <th>pcs_total</th>\n",
       "      <th>pcs_rumination</th>\n",
       "      <th>pcs_magnification</th>\n",
       "      <th>pcs_hopelessness</th>\n",
       "      <th>scltotal</th>\n",
       "      <th>...</th>\n",
       "      <th>phq_2</th>\n",
       "      <th>taps_1</th>\n",
       "      <th>taps_2</th>\n",
       "      <th>taps_3</th>\n",
       "      <th>taps_4</th>\n",
       "      <th>taps_5</th>\n",
       "      <th>ppiy_1</th>\n",
       "      <th>ppiy_2a</th>\n",
       "      <th>ppiy_3a</th>\n",
       "      <th>sleepduration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>baseline</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>bio0335</td>\n",
       "      <td>baseline</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>bio0337</td>\n",
       "      <td>baseline</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>bio0338</td>\n",
       "      <td>baseline</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>bio0339</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>bio0350</td>\n",
       "      <td>baseline</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1091 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id      time cpaq_willingness cpaq_activity_engagement  \\\n",
       "0           bio0001  baseline             18.0                      6.0   \n",
       "1           bio0001    month1             11.0                      7.0   \n",
       "2           bio0001    month2             10.0                      7.0   \n",
       "3           bio0001    month3             11.0                      5.0   \n",
       "4           bio0001    month6              8.0                      8.0   \n",
       "...             ...       ...              ...                      ...   \n",
       "1086        bio0335  baseline             14.0                     20.0   \n",
       "1087        bio0337  baseline             10.0                     21.0   \n",
       "1088        bio0338  baseline              8.0                     24.0   \n",
       "1089        bio0339  baseline              NaN                      NaN   \n",
       "1090        bio0350  baseline             11.0                     17.0   \n",
       "\n",
       "     cpaq_total pcs_total pcs_rumination pcs_magnification pcs_hopelessness  \\\n",
       "0          24.0      12.0            3.0               1.0              8.0   \n",
       "1          18.0      15.0            5.0               2.0              8.0   \n",
       "2          17.0       8.0            3.0               0.0              5.0   \n",
       "3          16.0       9.0            4.0               1.0              4.0   \n",
       "4          16.0      14.0            6.0               2.0              6.0   \n",
       "...         ...       ...            ...               ...              ...   \n",
       "1086       34.0       9.0            4.0               3.0              2.0   \n",
       "1087       31.0      13.0            4.0               3.0              6.0   \n",
       "1088       32.0       4.0            1.0               2.0              1.0   \n",
       "1089        NaN       NaN            NaN               NaN              NaN   \n",
       "1090       28.0      14.0            8.0               2.0              4.0   \n",
       "\n",
       "     scltotal  ... phq_2 taps_1 taps_2  taps_3  taps_4  taps_5  ppiy_1  \\\n",
       "0        23.0  ...   1.0    4.0    4.0     4.0     4.0     4.0     8.0   \n",
       "1        17.0  ...   1.0    4.0    4.0     4.0     4.0     4.0     9.0   \n",
       "2        18.0  ...   1.0    4.0    4.0     4.0     4.0     4.0     9.0   \n",
       "3        21.0  ...   1.0    4.0    4.0     4.0     4.0     4.0     8.0   \n",
       "4        22.0  ...   1.0    4.0    4.0     4.0     4.0     4.0    10.0   \n",
       "...       ...  ...   ...    ...    ...     ...     ...     ...     ...   \n",
       "1086     11.0  ...   1.0    4.0    4.0     4.0     4.0     4.0     6.0   \n",
       "1087      1.0  ...   1.0    4.0    4.0     4.0     4.0     4.0     4.0   \n",
       "1088      7.0  ...   0.0    4.0    4.0     4.0     4.0     4.0     3.0   \n",
       "1089      NaN  ...   NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
       "1090      8.0  ...   0.0    4.0    4.0     NaN     1.0     4.0     7.0   \n",
       "\n",
       "      ppiy_2a  ppiy_3a  sleepduration  \n",
       "0         5.0      6.0            7.0  \n",
       "1         6.0      4.0            6.0  \n",
       "2         6.0      6.0            6.0  \n",
       "3         6.0      6.0            6.0  \n",
       "4         6.0      5.0            6.0  \n",
       "...       ...      ...            ...  \n",
       "1086      5.0      5.0            7.5  \n",
       "1087      2.0      1.0            5.5  \n",
       "1088      2.0      2.0            6.0  \n",
       "1089      NaN      NaN            NaN  \n",
       "1090      2.0      0.0            7.0  \n",
       "\n",
       "[1091 rows x 27 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_df = pd.read_csv(f'{project_dir}/Data/raw_data/PROs/converted_sleep_duration.csv')\n",
    "# merge based on participant_id and time\n",
    "score_df = score_df.merge(sleep_df[['participant_id', 'time', 'Converted']], on=['participant_id', 'time'], how='left')\n",
    "score_df.rename(columns={'Converted': 'sleepduration'}, inplace=True)\n",
    "\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "897ccf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['participant_id', 'time', 'cpaq_willingness',\n",
       "       'cpaq_activity_engagement', 'cpaq_total', 'pcs_total', 'pcs_rumination',\n",
       "       'pcs_magnification', 'pcs_hopelessness', 'scltotal', 'pseqtotal',\n",
       "       'gadtotal', 'tsktotal', 'working_not_working', 'pain_frequency',\n",
       "       'life_limitation', 'describe_pain_number', 'phq_2', 'taps_1', 'taps_2',\n",
       "       'taps_3', 'taps_4', 'taps_5', 'ppiy_1', 'ppiy_2a', 'ppiy_3a',\n",
       "       'sleepduration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7308eef0",
   "metadata": {},
   "source": [
    "# combining PROMIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16d568c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "promis_only_score_df = pd.DataFrame({'participant_id': score_df['participant_id'], 'time': score_df['time']})\n",
    "include_pi = True\n",
    "if include_pi:\n",
    "\n",
    "    promis_list = ['anger', 'anxiety', 'depression', 'painbe', 'sleep', 'fatigue', 'emotional', 'physical', 'satisfaction', 'social', 'sleepim', 'upperex', 'painin']\n",
    "else:\n",
    "    promis_list = ['anger', 'anxiety', 'depression', 'painbe', 'sleep', 'fatigue', 'emotional', 'physical', 'satisfaction', 'social', 'sleepim', 'upperex']\n",
    "\n",
    "for promis in promis_list:\n",
    "    promis_df = pd.read_csv(f'{project_dir}/Data/raw_data/PROs/{promis}.csv', skiprows=4)\n",
    "    promis_df['participant_id'] = promis_df['PIN'].apply(FormatSubID)\n",
    "    promis_df['time'] = promis_df['Assmnt'].apply(FormatSessionPromis)\n",
    "    promis_df = promis_df[promis_df['participant_id'] != \"\"]\n",
    "    promis_df = promis_df[promis_df['time'] != \"\"]\n",
    "    \n",
    "    score_df = score_df.merge(promis_df[['participant_id', 'time', 'TScore']], on=['participant_id', 'time'], how='left')\n",
    "    score_df.rename(columns={'TScore': f'PROMIS-{promis}_T'}, inplace=True)\n",
    "\n",
    "    promis_only_score_df = promis_only_score_df.merge(promis_df[['participant_id', 'time', 'TScore']], on=['participant_id', 'time'], how='left')\n",
    "    promis_only_score_df.rename(columns={'TScore': f'PROMIS-{promis}_T'}, inplace=True)\n",
    "\n",
    "promis_only_score_df.rename(columns={'participant_id': 'subject_id', 'time': 'session'}, inplace=True)    \n",
    "promis_only_score_df.to_csv(f'{project_dir}/Data/cleaned_data/promis_only.csv', index=False)\n",
    "\n",
    "# break into time points\n",
    "\n",
    "target_dir = '/Volumes/Projects/HEAL_dataset_dev/'\n",
    "score_df.rename(columns={'participant_id': 'subject_id', 'time': 'session'}, inplace=True)\n",
    "for session in score_df['session'].unique():\n",
    "    score_df[score_df['session']==session].to_csv(f'{target_dir}/ses-{session}/PROs/ses-{session}_desc-PRO.csv', index=False)\n",
    "\n",
    "score_df.to_csv(f'{project_dir}/Data/cleaned_data/PROs_ses-all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec2afd",
   "metadata": {},
   "source": [
    "##  save score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "271119dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into time points\n",
    "\n",
    "target_dir = '/Volumes/Projects/HEAL_dataset_dev/'\n",
    "score_df.rename(columns={'participant_id': 'subject_id', 'time': 'session'}, inplace=True)\n",
    "for session in score_df['session'].unique():\n",
    "    score_df[score_df['session']==session].to_csv(f'{target_dir}/ses-{session}/PROs/ses-{session}_desc-PRO.csv', index=False)\n",
    "\n",
    "score_df.to_csv(f'{project_dir}/Data/cleaned_data/PROs_ses-all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7bf73",
   "metadata": {},
   "source": [
    "# save PainIn separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "040ca509",
   "metadata": {},
   "outputs": [],
   "source": [
    "promis = 'painin'\n",
    "threshold = 65\n",
    "promis_df = pd.read_csv(f'{project_dir}/Data/raw_data/PROs/{promis}.csv', skiprows=4)\n",
    "target_dir = '/Volumes/Projects/HEAL_dataset_dev/'\n",
    "promis_df['subject_id'] = promis_df['PIN'].apply(FormatSubID)\n",
    "promis_df['session'] = promis_df['Assmnt'].apply(FormatSessionPromis)\n",
    "promis_df = promis_df[promis_df['subject_id'] != \"\"]\n",
    "promis_df = promis_df[promis_df['session'] != \"\"]\n",
    "promis_df['group'] = promis_df['TScore'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "promis_df = promis_df[['subject_id', 'session', 'TScore', 'group']]\n",
    "promis_df.to_csv(f'{project_dir}/Data/cleaned_data/PROs_{promis}_threshold-{threshold}.csv', index=False)\n",
    "promis_df.to_csv(f'{project_dir}/labels.csv', index=False) # labels for prediction models\n",
    "for session in promis_df['session'].unique():\n",
    "    promis_df[promis_df['session']==session].to_csv(f'{target_dir}/ses-{session}/PROs/ses-{session}_desc-{promis}_threshold-{threshold}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00c5b649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/yiyuwang/Desktop/SNAPL/Projects/HEAL_prediction'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a6d2c",
   "metadata": {},
   "source": [
    "# preprocessing EEG, MRI parcellation, demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5684aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_year(number):\n",
    "    number = str(number).split('/')[2]\n",
    "\n",
    "    try:\n",
    "        year = int(number)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Input must be a valid number\")\n",
    "    if year < 0 or year > 99:\n",
    "        raise ValueError(\"Input must be between 00 and 99\")\n",
    "    if year < 25:\n",
    "        return 2000 + year\n",
    "    return 1900 + year\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_number = \"6/8/02\"\n",
    "converted_number = convert_to_year(input_number)\n",
    "print(converted_number)\n",
    "\n",
    "\n",
    "# Kaisa provided the raw csv from oncore (accural_results.csv)\n",
    "demographic_df = pd.read_csv(f'../Data/raw_data/PROS/demographics_oncore_jun2024.csv', skiprows=4).astype(str)\n",
    "demographic_df['StudyYear'] = demographic_df['On Study Date'].apply(convert_to_year)\n",
    "demographic_df['BirthYear'] =demographic_df['Birth Date'].apply(convert_to_year)\n",
    "\n",
    "demographic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1577e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all EEG apriori cluster\n",
    "\n",
    "which_type = 'source'\n",
    "which_source = 'aprioriCluster' # or which_source = ''\n",
    "eeg_dir = f'/Volumes/mackeylab/Mackeylab/Individual_Folders/YiyuWang/HEAL_EEG/{which_type}/{which_source}/'\n",
    "\n",
    "for session_id in range(5):\n",
    "    if session_id == 0:\n",
    "        df = pd.read_csv(eeg_dir + f'0{session_id}_mergedRECREOdB.csv')\n",
    "        # replace \"_REC_0{session_id}\" with empty string in column names to keep column names consistent across sessions\n",
    "        df.columns = [col.replace(f'_REC_0{session_id}', '') for col in df.columns]\n",
    "        df['session'] = 'baseline'\n",
    "\n",
    "    else:\n",
    "        ses_df = pd.read_csv(eeg_dir + f'0{session_id}_mergedRECREOdB.csv')\n",
    "        ses_df.columns = [col.replace(f'_REC_0{session_id}', '') for col in ses_df.columns]\n",
    "        \n",
    "        \n",
    "        if session_id == 4:\n",
    "            ses_df['session'] = 'month6'\n",
    "        else:     \n",
    "            ses_df['session'] = f'month{session_id}'\n",
    "        df = pd.concat([df, ses_df])    \n",
    "df.rename(columns={'subnum': 'subject_id'}, inplace=True)   \n",
    "# move session to the second column\n",
    "df = df[['subject_id', 'session'] + [col for col in df.columns if col != 'subject_id' and col != 'session']]\n",
    "# zscore by row (not including the study_id and session column)\n",
    "df.iloc[:, 2:] = df.iloc[:, 2:].apply(lambda row: (row - row.mean()) / row.std(), axis=1)\n",
    "df.to_csv(f'HEAL_EEG_{which_type}_{which_source}.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfc2ba30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>session</th>\n",
       "      <th>REC2_1</th>\n",
       "      <th>REC2_2</th>\n",
       "      <th>REC2_3</th>\n",
       "      <th>REC2_4</th>\n",
       "      <th>REC2_5</th>\n",
       "      <th>REC2_6</th>\n",
       "      <th>REC2_7</th>\n",
       "      <th>REC2_8</th>\n",
       "      <th>...</th>\n",
       "      <th>REO2_9891</th>\n",
       "      <th>REO2_9892</th>\n",
       "      <th>REO2_9893</th>\n",
       "      <th>REO2_9894</th>\n",
       "      <th>REO2_9895</th>\n",
       "      <th>REO2_9896</th>\n",
       "      <th>REO2_9897</th>\n",
       "      <th>REO2_9898</th>\n",
       "      <th>REO2_9899</th>\n",
       "      <th>REO2_9900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.635529</td>\n",
       "      <td>0.577702</td>\n",
       "      <td>0.493721</td>\n",
       "      <td>0.390051</td>\n",
       "      <td>0.275858</td>\n",
       "      <td>0.160531</td>\n",
       "      <td>0.052460</td>\n",
       "      <td>-0.042753</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bio0002</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.184276</td>\n",
       "      <td>0.077811</td>\n",
       "      <td>-0.019691</td>\n",
       "      <td>-0.103823</td>\n",
       "      <td>-0.171910</td>\n",
       "      <td>-0.223638</td>\n",
       "      <td>-0.260548</td>\n",
       "      <td>-0.285547</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bio0003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bio0004</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bio0005</td>\n",
       "      <td>baseline</td>\n",
       "      <td>-0.400284</td>\n",
       "      <td>-0.465622</td>\n",
       "      <td>-0.525068</td>\n",
       "      <td>-0.576268</td>\n",
       "      <td>-0.617913</td>\n",
       "      <td>-0.650042</td>\n",
       "      <td>-0.673683</td>\n",
       "      <td>-0.690568</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>bio0248</td>\n",
       "      <td>month6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>bio0251</td>\n",
       "      <td>month6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>bio0258</td>\n",
       "      <td>month6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>bio0259</td>\n",
       "      <td>month6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>bio0261</td>\n",
       "      <td>month6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>906 rows × 19802 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id   session    REC2_1    REC2_2    REC2_3    REC2_4    REC2_5  \\\n",
       "0      bio0001  baseline  0.635529  0.577702  0.493721  0.390051  0.275858   \n",
       "1      bio0002  baseline  0.184276  0.077811 -0.019691 -0.103823 -0.171910   \n",
       "2      bio0003  baseline       NaN       NaN       NaN       NaN       NaN   \n",
       "3      bio0004  baseline       NaN       NaN       NaN       NaN       NaN   \n",
       "4      bio0005  baseline -0.400284 -0.465622 -0.525068 -0.576268 -0.617913   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "131    bio0248    month6       NaN       NaN       NaN       NaN       NaN   \n",
       "132    bio0251    month6       NaN       NaN       NaN       NaN       NaN   \n",
       "133    bio0258    month6       NaN       NaN       NaN       NaN       NaN   \n",
       "134    bio0259    month6       NaN       NaN       NaN       NaN       NaN   \n",
       "135    bio0261    month6       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       REC2_6    REC2_7    REC2_8  ...  REO2_9891  REO2_9892  REO2_9893  \\\n",
       "0    0.160531  0.052460 -0.042753  ...        NaN        NaN        NaN   \n",
       "1   -0.223638 -0.260548 -0.285547  ...        NaN        NaN        NaN   \n",
       "2         NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "3         NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "4   -0.650042 -0.673683 -0.690568  ...        NaN        NaN        NaN   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "131       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "132       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "133       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "134       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "135       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
       "\n",
       "     REO2_9894  REO2_9895  REO2_9896  REO2_9897  REO2_9898  REO2_9899  \\\n",
       "0          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "131        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "132        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "133        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "134        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "135        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "     REO2_9900  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "..         ...  \n",
       "131        NaN  \n",
       "132        NaN  \n",
       "133        NaN  \n",
       "134        NaN  \n",
       "135        NaN  \n",
       "\n",
       "[906 rows x 19802 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfac83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all EEG\n",
    "\n",
    "which_type = 'source'\n",
    "which_source = 'aprioriCluster' # or which_source = ''\n",
    "eeg_dir = f'/Volumes/mackeylab/Mackeylab/Individual_Folders/YiyuWang/HEAL_EEG/{which_type}/'\n",
    "\n",
    "for session_id in range(5):\n",
    "    if session_id == 0:\n",
    "        if which_type == 'scalp':\n",
    "            df = pd.read_csv(eeg_dir + f'mergedScalpEEG_REC_REO_0{session_id}.csv')\n",
    "        elif which_type == 'source':   \n",
    "            df = pd.read_csv(eeg_dir + f'mergedEEGIC_REC_REO_0{session_id}.csv')\n",
    "        # replace \"_REC_0{session_id}\" with empty string in column names to keep column names consistent across sessions\n",
    "        df.columns = [col.replace(f'_REC_0{session_id}', '') for col in df.columns]\n",
    "        df['session'] = 'baseline'\n",
    "\n",
    "    else:\n",
    "        if which_type == 'scalp':\n",
    "            ses_df = pd.read_csv(eeg_dir + f'mergedScalpEEG_REC_REO_0{session_id}.csv')\n",
    "        elif which_type == 'source':   \n",
    "            ses_df = pd.read_csv(eeg_dir + f'mergedEEGIC_REC_REO_0{session_id}.csv')\n",
    "        \n",
    "        ses_df.columns = [col.replace(f'_REC_0{session_id}', '') for col in ses_df.columns]\n",
    "        \n",
    "        \n",
    "        if session_id == 4:\n",
    "            ses_df['session'] = 'month6'\n",
    "        else:     \n",
    "            ses_df['session'] = f'month{session_id}'\n",
    "        df = pd.concat([df, ses_df])    \n",
    "df.rename(columns={'subNum': 'subject_id'}, inplace=True)   \n",
    "# move session to the second column\n",
    "df = df[['subject_id', 'session'] + [col for col in df.columns if col != 'subject_id' and col != 'session']]\n",
    "# zscore by row (not including the study_id and session column)\n",
    "df.iloc[:, 2:] = df.iloc[:, 2:].apply(lambda row: (row - row.mean()) / row.std(), axis=1)\n",
    "df.to_csv(f'HEAL_EEG_{which_type}.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a908f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all EEG\n",
    "\n",
    "\n",
    "eeg_dir = '/Volumes/mackeylab/Mackeylab/Individual_Folders/YiyuWang/HEAL_EEG/Scalp/'\n",
    "\n",
    "for session_id in range(5):\n",
    "    if session_id == 0:\n",
    "        df = pd.read_csv(eeg_dir + f'mergedScalpEEG_REC_REO_0{session_id}.csv')\n",
    "        # replace \"_REC_0{session_id}\" with empty string in column names to keep column names consistent across sessions\n",
    "        df.columns = [col.replace(f'_REC_0{session_id}', '') for col in df.columns]\n",
    "        df['session'] = 'baseline'\n",
    "\n",
    "    else:\n",
    "        ses_df = pd.read_csv(eeg_dir + f'mergedScalpEEG_REC_REO_0{session_id}.csv')\n",
    "        ses_df.columns = [col.replace(f'_REC_0{session_id}', '') for col in ses_df.columns]\n",
    "        df = pd.concat([df, ses_df])\n",
    "        \n",
    "        if session_id == 4:\n",
    "            df['session'] = 'month6'\n",
    "        else:     \n",
    "            df['session'] = f'month{session_id}'\n",
    "df.rename(columns={'subNum': 'study_id'}, inplace=True)   \n",
    "# move session to the second column\n",
    "df = df[['study_id', 'session'] + [col for col in df.columns if col != 'study_id' and col != 'session']]\n",
    "\n",
    "df.to_csv(f'HEAL_EEG_scalp.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b5c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcellation = 'schaefer400'\n",
    "parcellation_source_dir =f'/Users/yiyuwang/Downloads/{parcellation}'\n",
    "\n",
    "# combine all participants:\n",
    "\n",
    "parcellation_files = glob.glob(parcellation_source_dir + f'/sub-*_task-rest_run-1_parcellation-{parcellation}.csv')\n",
    "parcellation_files = np.sort(parcellation_files)\n",
    "# for f in parcellation_files:\n",
    "#     os.system(f'cp -r {f} {parcellation_source_dir}/task-rest_run-1/')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Concatenate the CSV files into a big dataframe\n",
    "for i, file in enumerate(parcellation_files):\n",
    "    sub_df = pd.read_csv(file)\n",
    "    sub_id = file.split('sub-')[1].split('_task')[0]\n",
    "    sub_df['study_id'] = FormatSubID(sub_id)\n",
    "    if i == 0:\n",
    "        df = sub_df\n",
    "    else:    \n",
    "        df = pd.concat([df, sub_df])\n",
    "# drop unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# move study_id to the first column\n",
    "df = df[['study_id'] + [col for col in df.columns if col != 'study_id']]\n",
    "# drop the first column\n",
    "# Save the big dataframe as a new CSV file\n",
    "df.to_csv(f'HEAL_MRI_task-rest_parcellation-{parcellation}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71ad0ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ROI scheme - schaefer200\n"
     ]
    }
   ],
   "source": [
    "# create parcellation for pressure glm:\n",
    "import pandas as pd\n",
    "import glob, sys\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker, NiftiMapsMasker\n",
    "import warnings\n",
    "data_dir = '/Volumes/mackeylab/Mackeylab/Individual_Folders/Kaisa/fmri_results/univariate/model1_stimulation/1stlvl'\n",
    "parcellation = 'schaefer400'\n",
    "\n",
    "mask_img = f'{project_dir}/masks/tpl-MNI152NLin6Asym_res-02_desc-brain_mask.nii'\n",
    "\n",
    "\n",
    "\n",
    "ROI_scheme = 'schaefer'\n",
    "NROI = 200\n",
    "if ROI_scheme == 'schaefer':\n",
    "    NROI = int(NROI) # NROI will not be used if ROI_scheme is msdl\n",
    "    ROI_scheme = f'schaefer{NROI}'\n",
    "print(f'using ROI scheme - {ROI_scheme}')\n",
    "\n",
    "if ROI_scheme == 'msdl':\n",
    "    atlas = datasets.fetch_atlas_msdl()\n",
    "    masker = NiftiMapsMasker(\n",
    "        maps_img=atlas['maps'],\n",
    "        resampling_target=\"mask\",\n",
    "        t_r=0.8,\n",
    "        detrend=True,\n",
    "        memory=f'{project_dir}/nilearn',\n",
    "        mask_img = mask_img,\n",
    "        standardize=\"zscore_sample\",\n",
    "        standardize_confounds=\"zscore_sample\",\n",
    "        verbose=0\n",
    "    )\n",
    "elif 'schaefer' in ROI_scheme:\n",
    "    atlas = datasets.fetch_atlas_schaefer_2018(n_rois=NROI,resolution_mm=2)\n",
    "    masker = NiftiLabelsMasker(\n",
    "        labels_img=atlas['maps'],\n",
    "        labels=atlas['labels'],\n",
    "        t_r = 0.8,\n",
    "        detrend=True,\n",
    "        standardize=True,\n",
    "        memory=f'{project_dir}/nilearn',\n",
    "        mask_img = mask_img,\n",
    "        verbose=0)\n",
    "\n",
    "save_dir = f'/Users/yiyuwang/Desktop/SNAPL/Projects/HEAL_prediction/Data/cleaned_data'\n",
    "file_list = glob.glob(f'{data_dir}/*/sub-*_stat-z_reg-stimulation_gm_masked.nii.gz')\n",
    "save_file_path = save_dir + f'/HEAL_MRI_task-pressure_run-1_desc-pain_parcellation-{ROI_scheme}.csv'\n",
    "run = 1\n",
    "for i, file in enumerate(file_list):\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    s = file_name.split(f'sub-')[1].split('_stat-z')[0]\n",
    "    \n",
    "    \n",
    "    if os.path.exists(file):\n",
    "        fmri_img = nib.load(glob.glob(file)[0])\n",
    "        parcellated_data = masker.fit_transform(fmri_img)\n",
    "\n",
    "        # save parcellation to df\n",
    "        parcellated_data_df = pd.DataFrame(parcellated_data,columns=atlas['labels'])\n",
    "\n",
    "        # concatenate the parcellated data with the study_id\n",
    "        parcellated_data_df['subject_id'] = FormatSubID(s)\n",
    "        parcellated_data_df = parcellated_data_df[['subject_id'] + [col for col in parcellated_data_df.columns if col != 'subject_id']]\n",
    "\n",
    "        if i == 0:\n",
    "            df = parcellated_data_df\n",
    "        else:\n",
    "            df = pd.concat([df, parcellated_data_df])    \n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(f\"{file} func file does not exist!\")\n",
    "        continue\n",
    "\n",
    "df.to_csv(save_file_path, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e8027a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Projects/HEAL_dataset_dev/ses-month1/Actigraphy/sub-bio0045_ses-month1_desc-actigraphy.csv 20092\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month1/Actigraphy/sub-bio0037_ses-month1_desc-actigraphy.csv 20084\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month2/Actigraphy/sub-bio0020_ses-month2_desc-actigraphy.csv 20155\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month2/Actigraphy/sub-bio0047_ses-month2_desc-actigraphy.csv 20091\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month2/Actigraphy/sub-bio0038_ses-month2_desc-actigraphy.csv 20084\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0155_ses-month3_desc-actigraphy.csv 20341\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0022_ses-month3_desc-actigraphy.csv 20192\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0152_ses-month3_desc-actigraphy.csv 20198\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0161_ses-month3_desc-actigraphy.csv 20206\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0142_ses-month3_desc-actigraphy.csv 20207\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0159_ses-month3_desc-actigraphy.csv 20201\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0023_ses-month3_desc-actigraphy.csv 20206\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0205_ses-month3_desc-actigraphy.csv 20222\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0009_ses-month6_desc-actigraphy.csv 13348\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0211_ses-month6_desc-actigraphy.csv 20132\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0073_ses-month6_desc-actigraphy.csv 20196\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0010_ses-month6_desc-actigraphy.csv 23161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0205_ses-month6_desc-actigraphy.csv 20094\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0111_ses-month6_desc-actigraphy.csv 22014\n"
     ]
    }
   ],
   "source": [
    "len_list, file_list = [], []\n",
    "for session in ['baseline', 'month1', 'month2', 'month3', 'month6']:\n",
    "    actigraphy_dir = f'/Volumes/Projects/HEAL_dataset_dev/ses-{session}/Actigraphy/'\n",
    "    actigraphy_files = glob.glob(actigraphy_dir + 'sub-*.csv')\n",
    "    for i, file in enumerate(actigraphy_files):\n",
    "        sub_df = pd.read_csv(file)\n",
    "        file_len = len(sub_df)\n",
    "        len_list.append(file_len)\n",
    "        file_list.append(file)\n",
    "        if file_len != 20161:\n",
    "            print(file, file_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a95e5ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "saving baseline\n",
      "2358837\n",
      "month1\n",
      "saving month1\n",
      "2237725\n",
      "month2\n",
      "saving month2\n",
      "2298201\n",
      "month3\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0022_ses-month3_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0023_ses-month3_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0142_ses-month3_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0152_ses-month3_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0155_ses-month3_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0159_ses-month3_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0161_ses-month3_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month3/Actigraphy/sub-bio0205_ses-month3_desc-actigraphy.csv, 20161\n",
      "saving month3\n",
      "2298354\n",
      "month6\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0010_ses-month6_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0073_ses-month6_desc-actigraphy.csv, 20161\n",
      "/Volumes/Projects/HEAL_dataset_dev/ses-month6/Actigraphy/sub-bio0111_ses-month6_desc-actigraphy.csv, 20161\n",
      "saving month6\n",
      "2311606\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# concatenate all actigraphy data:\n",
    "for session in ['baseline', 'month1', 'month2', 'month3', 'month6']:\n",
    "    actigraphy_dir = f'/Volumes/Projects/HEAL_dataset_dev/ses-{session}/Actigraphy/'\n",
    "    actigraphy_files = glob.glob(actigraphy_dir + 'sub-*.csv')\n",
    "    actigraphy_files = np.sort(actigraphy_files)\n",
    "    print(session)\n",
    "    for i, file in enumerate(actigraphy_files):\n",
    "        sub_df = pd.read_csv(file)\n",
    "        sub_id = file.split('sub-')[1].split(f'_ses-{session}')[0]\n",
    "        sub_df['study_id'] = FormatSubID(sub_id)\n",
    "        sub_df['session'] = session\n",
    "        if sub_df.shape[0] > 20161:\n",
    "            sub_df = sub_df.iloc[:20161]\n",
    "            print(f'{file}, {sub_df.shape[0]}')\n",
    "        \n",
    "        if i == 0:\n",
    "            df = sub_df\n",
    "        else:    \n",
    "            df = pd.concat([df, sub_df])\n",
    "    print(f\"saving {session}\")\n",
    "    df.to_csv(f'HEAL_actigraphy_ses-{session}_timeseries.csv', index=False)\n",
    "    print(len(df))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a25dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117,)\n",
      "(111,)\n",
      "(114,)\n",
      "(114,)\n",
      "(115,)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('HEAL_actigraphy_ses-baseline_timeseries.csv')\n",
    "print(np.unique(test.study_id).shape)\n",
    "test = pd.read_csv('HEAL_actigraphy_ses-month1_timeseries.csv')\n",
    "print(np.unique(test.study_id).shape)\n",
    "test = pd.read_csv('HEAL_actigraphy_ses-month2_timeseries.csv')\n",
    "print(np.unique(test.study_id).shape)\n",
    "test = pd.read_csv('HEAL_actigraphy_ses-month3_timeseries.csv')\n",
    "print(np.unique(test.study_id).shape)\n",
    "test = pd.read_csv('HEAL_actigraphy_ses-month6_timeseries.csv')\n",
    "print(np.unique(test.study_id).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8c0142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "month1\n",
      "month2\n",
      "month3\n",
      "month6\n",
      "571\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# concatenate all actigraphy data:\n",
    "counter = 0\n",
    "for session in ['baseline', 'month1', 'month2', 'month3', 'month6']:\n",
    "    actigraphy_dir = f'/Volumes/Projects/HEAL_dataset_dev/ses-{session}/Actigraphy/'\n",
    "    actigraphy_files = glob.glob(actigraphy_dir + 'sub-*.csv')\n",
    "    actigraphy_files = np.sort(actigraphy_files)\n",
    "    print(session)\n",
    "    for i, file in enumerate(actigraphy_files):\n",
    "        sub_df = pd.read_csv(file)\n",
    "        sub_id = file.split('sub-')[1].split(f'_ses-{session}')[0]\n",
    "        sub_df['study_id'] = FormatSubID(sub_id)\n",
    "        sub_df['session'] = session\n",
    "        counter += 1\n",
    "    \n",
    "        #if sub_df.shape[0] != 20161:\n",
    "        #    print(f'{file}, {sub_df.shape[0]}')\n",
    "        #sub_file_save_path = f'/Users/yiyuwang/Library/CloudStorage/OneDrive-Stanford/HEAL_Actigraphy/ses-{session}/sub-{sub_id}_ses-{session}_actigraphy.csv'\n",
    "        #sub_df.to_csv(sub_file_save_path, index=False)  \n",
    "    print(f\"{session} {counter}\")\n",
    "print(counter)        #        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46faa498",
   "metadata": {},
   "source": [
    "# ------------------------- end here 2024/06/03 -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e5617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6867e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject_id', 'redcap_event_name', 'PainInT', 'DepT', 'AnxT', 'AngT', 'FatigeT', 'SleepDisT', 'SleepImpT', 'IsolationT', 'eSupportT', 'PhyFxT', 'cpaq_total', 'cpaq_willingness', 'cpaq_activity_engagement', 'pcs_score_rumination', 'pcs_score_magnification', 'pcs_score_helplessness', 'pcs_score_total', 'scltotal', 'pseqtotal', 'gadtotal', 'phqtotal', 'tsktotal', 'sleephrs', 'HICP3', 'pain_frequency', 'life_limitation', 'describe_pain_number', 'interferes_enjoyment', 'interferes_general_activity', 'working_not_working', 'taps_1', 'taps_2', 'taps_3', 'taps_4', 'taps_5', 'ppiy_1', 'ppiy_2a', 'ppiy_3a']\n"
     ]
    }
   ],
   "source": [
    "# list of columns to keep:\n",
    "\n",
    "col_to_keep = ['subject_id', 'redcap_event_name', \n",
    "                'PainInT', 'DepT',\t'AnxT',\t'AngT',\t'FatigeT', 'SleepDisT',\t'SleepImpT', 'IsolationT', 'eSupportT',\t'PhyFxT',\n",
    "               'cpaq_total', 'cpaq_willingness', 'cpaq_activity_engagement', \n",
    "               'pcs_score_rumination',\t'pcs_score_magnification',\t'pcs_score_helplessness', 'pcs_score_total',\n",
    "               'scltotal', 'pseqtotal', 'gadtotal', 'phqtotal', 'tsktotal',\t\n",
    "               'sleephrs', 'HICP3','pain_frequency', 'life_limitation',\t'describe_pain_number',\t'interferes_enjoyment',\t'interferes_general_activity',\t'working_not_working',\n",
    "               'taps_1', 'taps_2', 'taps_3', 'taps_4',\t'taps_5',\n",
    "               'ppiy_1', 'ppiy_2a', 'ppiy_3a']\n",
    "\n",
    "\n",
    "# drop_cols = [\n",
    "#         'pain_frequency', \n",
    "#         'life_limitation',\n",
    "#         'describe_pain_number',\n",
    "#         'interferes_enjoyment',\n",
    "#         'interferes_general_activity', \n",
    "#         'working_not_working',\n",
    "#         'HICP3',\n",
    "#         'PainInT'\n",
    "# ]\n",
    "\n",
    "# col_to_keep = [x for x in col_to_keep if x not in drop_cols]\n",
    "print(col_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc053cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>session</th>\n",
       "      <th>PainInT</th>\n",
       "      <th>DepT</th>\n",
       "      <th>AnxT</th>\n",
       "      <th>AngT</th>\n",
       "      <th>FatigeT</th>\n",
       "      <th>SleepDisT</th>\n",
       "      <th>SleepImpT</th>\n",
       "      <th>IsolationT</th>\n",
       "      <th>...</th>\n",
       "      <th>interferes_general_activity</th>\n",
       "      <th>working_not_working</th>\n",
       "      <th>taps_1</th>\n",
       "      <th>taps_2</th>\n",
       "      <th>taps_3</th>\n",
       "      <th>taps_4</th>\n",
       "      <th>taps_5</th>\n",
       "      <th>ppiy_1</th>\n",
       "      <th>ppiy_2a</th>\n",
       "      <th>ppiy_3a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>baseline</td>\n",
       "      <td>73.2</td>\n",
       "      <td>51.2</td>\n",
       "      <td>52.5</td>\n",
       "      <td>49.8</td>\n",
       "      <td>66.1</td>\n",
       "      <td>63.2</td>\n",
       "      <td>64.9</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>47.6</td>\n",
       "      <td>45.9</td>\n",
       "      <td>48.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>61.6</td>\n",
       "      <td>68.0</td>\n",
       "      <td>48.1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>46.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>45.8</td>\n",
       "      <td>70.5</td>\n",
       "      <td>62.7</td>\n",
       "      <td>65.9</td>\n",
       "      <td>48.9</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month3</td>\n",
       "      <td>71.4</td>\n",
       "      <td>38.2</td>\n",
       "      <td>51.9</td>\n",
       "      <td>47.3</td>\n",
       "      <td>74.2</td>\n",
       "      <td>66.2</td>\n",
       "      <td>66.2</td>\n",
       "      <td>48.3</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bio0001</td>\n",
       "      <td>month6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id   session  PainInT  DepT  AnxT  AngT  FatigeT  SleepDisT  \\\n",
       "0    bio0001  baseline     73.2  51.2  52.5  49.8     66.1       63.2   \n",
       "1    bio0001    month1     71.7  47.6  45.9  48.9     67.4       61.6   \n",
       "2    bio0001    month2     71.7  46.3  47.3  45.8     70.5       62.7   \n",
       "3    bio0001    month3     71.4  38.2  51.9  47.3     74.2       66.2   \n",
       "4    bio0001    month6      NaN   NaN   NaN   NaN      NaN        NaN   \n",
       "\n",
       "   SleepImpT  IsolationT  ...  interferes_general_activity  \\\n",
       "0       64.9        52.6  ...                         10.0   \n",
       "1       68.0        48.1  ...                          8.0   \n",
       "2       65.9        48.9  ...                          9.0   \n",
       "3       66.2        48.3  ...                          8.0   \n",
       "4        NaN         NaN  ...                          7.0   \n",
       "\n",
       "   working_not_working  taps_1  taps_2  taps_3  taps_4  taps_5  ppiy_1  \\\n",
       "0                  1.0     4.0     4.0     4.0     4.0     4.0     8.0   \n",
       "1                  1.0     4.0     4.0     4.0     4.0     4.0     9.0   \n",
       "2                  1.0     4.0     4.0     4.0     4.0     4.0     9.0   \n",
       "3                  1.0     4.0     4.0     4.0     4.0     4.0     8.0   \n",
       "4                  1.0     4.0     4.0     4.0     4.0     4.0    10.0   \n",
       "\n",
       "   ppiy_2a  ppiy_3a  \n",
       "0      5.0      6.0  \n",
       "1      6.0      4.0  \n",
       "2      6.0      6.0  \n",
       "3      6.0      6.0  \n",
       "4      6.0      5.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_df['subject_id'] = pro_df['study_id'].apply(FormatSubID)\n",
    "pro_df_cleaned = pro_df[col_to_keep]\n",
    "\n",
    "pro_df_cleaned = pro_df_cleaned.rename(columns={'redcap_event_name':'session'})\n",
    "pro_df_cleaned['session'] = pro_df_cleaned['session'].replace({'baseline_arm_1': 'baseline', '1_month_followup_arm_1': 'month1', '2_month_followup_arm_1': 'month2', '3_month_followup_arm_1': 'month3', '6_month_followup_arm_1': 'month6'})\n",
    "# pro_df_cleaned = pro_df_cleaned.recode({'session': {'baseline_visit_arm_1': 'baseline', '1_month_followup_arm_1': '1month', '2_month_followup_arm_1': '2month', '3_month_followup_arm_1': '3month', '6_month_followup_arm_1': '6month'}})\n",
    "\n",
    "pro_head = pro_df_cleaned[['subject_id', 'session']]\n",
    "pro_df_cleaned_data = pro_df_cleaned.copy().drop(['subject_id', 'session'], axis=1).apply(pd.to_numeric, errors='coerce')\n",
    "pro_df_cleaned_data['sleephrs'] = pro_df_cleaned_data['sleephrs'].apply(lambda x: np.nan if x > 24 else x)\n",
    "pro_df_final = pro_head.join(pro_df_cleaned_data)\n",
    "pro_df_final.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23470fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned data, one csv for each session\n",
    "target_dir = '/Volumes/Projects/HEAL_dataset_dev'\n",
    "for session in pro_df_final['session'].unique():\n",
    "    pro_df_final[pro_df_final['session']==session].to_csv(f'{target_dir}/ses-{session}/PROs/ses-{session}_desc-PRO.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b94ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d653eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 65\n",
    "threshold_str = 65\n",
    "\n",
    "y_df = pro_df_final[['subject_id', 'session', 'PainInT']]\n",
    "\n",
    "y_df['ImpactGroup'] = y_df['PainInT'].apply(lambda x: 1 if x and x >= threshold else 0 if x else None)\n",
    "for session in y_df['session'].unique():\n",
    "    y_df[y_df['session']==session].to_csv(f'{target_dir}/ses-{session}/PROs/ses-{session}_desc-PainInT_threshold-{threshold}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba2a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n"
     ]
    }
   ],
   "source": [
    "def convert_to_year(number):\n",
    "    number = str(number).split('/')[2]\n",
    "    if len(number) != 2:\n",
    "        raise ValueError(\"Input must be a two-digit number\")\n",
    "    try:\n",
    "        year = int(number)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Input must be a valid number\")\n",
    "    if year < 0 or year > 99:\n",
    "        raise ValueError(\"Input must be between 00 and 99\")\n",
    "    if year < 25:\n",
    "        return 2000 + year\n",
    "    return 1900 + year\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_number = \"6/8/02\"\n",
    "converted_number = convert_to_year(input_number)\n",
    "print(converted_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec33da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demographic_df = pd.read_csv(f'raw_data/PROS/demographics_oncore.csv', skiprows=4, index_col=0)\n",
    "demographic_df['StudyYear'] = demographic_df['On Study Date'].apply(convert_to_year)\n",
    "demographic_df['BirthYear'] =demographic_df['Birth Date'].apply(convert_to_year)\n",
    "\n",
    "\n",
    "demographic_df['age'] = demographic_df['StudyYear'] - demographic_df['BirthYear']\n",
    "demographic_df['subject_id'] = demographic_df['Sequence No.'].apply(FormatSubID)\n",
    "demographic_df = demographic_df.rename(columns={'Biological Sex': 'sex'})\n",
    "demographic_cleaned_df = demographic_df[['subject_id', 'age', 'sex', 'Race', \"Ethnicity\"]]\n",
    "demographic_cleaned_df.sort_values('subject_id', inplace=True)\n",
    "demographic_cleaned_df.to_csv(f'{target_dir}/participants_demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a862143",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0e26c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
